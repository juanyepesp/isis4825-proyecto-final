{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ec84ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\camilo daza\\documents\\github\\isis4825-proyecto-final\\venv\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "                                count\n",
      "ImagenesFiltradas/train/images    610\n",
      "ImagenesFiltradas/val/images       74\n",
      "ImagenesFiltradas/test/images     226\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "%pip install ultralytics --upgrade --quiet\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "\n",
    "#Revisión Imagenes Originales\n",
    "from pathlib import Path\n",
    "ORIGINAL_IMAGES = Path('data/ImagenesOriginales/')\n",
    "if not ORIGINAL_IMAGES.exists():\n",
    "    raise FileNotFoundError(f\"Ruta de datos no encontrada: {ORIGINAL_IMAGES}\")\n",
    "\n",
    "#Revisión Imagenes Filtradas\n",
    "from pathlib import Path\n",
    "FILTERED_IMAGES = Path('data/ImagenesFiltradas/')\n",
    "if not FILTERED_IMAGES.exists():\n",
    "    raise FileNotFoundError(f\"Ruta de datos no encontrada: {FILTERED_IMAGES}\")\n",
    "\n",
    "DATA_ROOT = Path('data/')\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Ruta de datos no encontrada: {DATA_ROOT}\")\n",
    "\n",
    "root = DATA_ROOT\n",
    "train_img_orig = root / 'ImagenesOriginales' / 'train'\n",
    "train_img_fil = root / 'ImagenesFiltradas' / 'train'\n",
    "train_lbl = root / 'EtiquetasProcesadas' / 'train'\n",
    "\n",
    "# Definir clases\n",
    "class_names = [\n",
    "    'carretera', 'rio'\n",
    "]\n",
    "\n",
    "##Tabla de conteo por grupo\n",
    "counts = {}\n",
    "for split in ['ImagenesFiltradas/train/images', 'ImagenesFiltradas/val/images', 'ImagenesFiltradas/test/images']:\n",
    "    path = root / split \n",
    "    counts[split] = len(list(path.glob('*.*'))) if path.exists() else 0\n",
    "\n",
    "# Mostrar tabla de distribución\n",
    "dist = pd.Series(counts, name='count')\n",
    "print(dist.to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af722a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained YOLOv11 model\n",
    "model = YOLO('yolo11l.pt')  \n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2cf34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 0 / 25,372,160 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Freeze the backbone - only train the head\n",
    "model.model.freeze = ['model.0', 'model.1', 'model.2', 'model.3', 'model.4', 'model.5', 'model.6', \n",
    "                       'model.7', 'model.8', 'model.9', 'model.10', 'model.11', 'model.12', 'model.13']\n",
    "\n",
    "# Count trainable vs total parameters\n",
    "trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc025d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rapid fine-tuning...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data\\rio-carretera-differentiation_orig.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=14, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=model2.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rapid_finetune10, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=3, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,312,022 parameters, 25,312,006 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 180/1015 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.10.cv1.conv.weight'\n",
      "Freezing layer 'model.10.cv1.bn.weight'\n",
      "Freezing layer 'model.10.cv1.bn.bias'\n",
      "Freezing layer 'model.10.cv2.conv.weight'\n",
      "Freezing layer 'model.10.cv2.bn.weight'\n",
      "Freezing layer 'model.10.cv2.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.bias'\n",
      "Freezing layer 'model.13.cv1.conv.weight'\n",
      "Freezing layer 'model.13.cv1.bn.weight'\n",
      "Freezing layer 'model.13.cv1.bn.bias'\n",
      "Freezing layer 'model.13.cv2.conv.weight'\n",
      "Freezing layer 'model.13.cv2.bn.weight'\n",
      "Freezing layer 'model.13.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on Quadro T1000 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.2 ms, read: 50.326.3 MB/s, size: 53.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesOriginales\\train\\labels.cache... 610 images, 0 backgrounds, 0 corrupt: 100%|██████████| 610/610 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 485.767.9 MB/s, size: 66.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesOriginales\\val\\labels.cache... 74 images, 0 backgrounds, 0 corrupt: 100%|██████████| 74/74 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      4.37G      2.584      3.023      2.527          9        640: 100%|██████████| 77/77 [04:22<00:00,  3.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:11<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.458      0.274      0.212     0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      4.02G      2.289      2.641      2.263          5        640: 100%|██████████| 77/77 [03:54<00:00,  3.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:14<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.483      0.337      0.401      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      4.01G      2.241      2.538      2.257         13        640: 100%|██████████| 77/77 [03:02<00:00,  2.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:14<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.444      0.597      0.476      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      4.02G      2.141      2.423      2.165         14        640: 100%|██████████| 77/77 [06:02<00:00,  4.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:27<00:00,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124       0.52      0.542      0.484      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      4.02G      2.126      2.407      2.132          3        640: 100%|██████████| 77/77 [05:22<00:00,  4.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:13<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.428      0.597      0.429      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      4.02G      2.147      2.373      2.136          9        640: 100%|██████████| 77/77 [02:39<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:14<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.454      0.499       0.41      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      3.99G      2.104      2.317       2.12          8        640: 100%|██████████| 77/77 [02:28<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:10<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.619      0.524      0.516      0.179\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 epochs completed in 0.497 hours.\n",
      "Optimizer stripped from c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\last.pt, 51.2MB\n",
      "Optimizer stripped from c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.pt, 51.2MB\n",
      "\n",
      "Validating c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:08<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124       0.52      0.542      0.484      0.195\n",
      "             carretera         33         62      0.441      0.435      0.336      0.142\n",
      "                   rio         45         62      0.598      0.649      0.632      0.247\n",
      "Speed: 1.1ms preprocess, 111.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\u001b[0m\n",
      "Fine-tuning completed in 1830.21 seconds\n",
      "Trainable parameters: 0 / 25,312,022 (0.0%)\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CPU (Intel Core(TM) i7-10850H 2.70GHz)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (48.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.53'] not found, attempting AutoUpdate...\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  6.5s, saved as 'c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.onnx' (96.7 MB)\n",
      "\n",
      "Export complete (8.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune10\\weights\\best.onnx imgsz=640 data=data\\rio-carretera-differentiation_orig.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model saved to custom_rio_carretera_X_Orig.pt\n"
     ]
    }
   ],
   "source": [
    "#Modelo Originales\n",
    "\n",
    "# Define paths\n",
    "root = Path('data')\n",
    "yaml_path = root / 'rio-carretera-differentiation_orig.yaml'\n",
    "\n",
    "#Fine Tune / Correr Modelo\n",
    "print(\"Starting rapid fine-tuning...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('runs/detect', exist_ok=True)\n",
    "\n",
    "# Train with minimal epochs and a small batch size for quick results\n",
    "results = model.train(\n",
    "    data=str(yaml_path),              # Path to your data YAML\n",
    "    epochs=20,                         # Very few epochs for fast adaptation\n",
    "    imgsz=640,                        # Image size\n",
    "    batch=8,                          # Smaller batch size\n",
    "    patience=3,                       # Early stopping patience\n",
    "    name='rapid_finetune',            # Run name\n",
    "    pretrained=True,                  # Use pretrained weights\n",
    "    freeze=14,                        # Alternative way to freeze layers\n",
    "    optimizer='Adam',                 # Adam optimizer converges faster for fine-tuning\n",
    "    lr0=0.001,                        # Lower learning rate for fine-tuning\n",
    "    device='0' if torch.cuda.is_available() else 'cpu' # Use GPU if available\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Fine-tuning completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Count trainable vs total parameters\n",
    "trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.1%})\")\n",
    "\n",
    "# Save the model\n",
    "model.export(format=\"onnx\")  # Export to ONNX format for deployment\n",
    "model.save('model3_Orig.pt')\n",
    "print(f\"model3_Orig.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac55380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: model3_Orig.pt\n",
      "\n",
      "Mapeo de clases del modelo:\n",
      "  Class 0: carretera\n",
      "  Class 1: rio\n",
      "\n",
      "Evaluando el modelo fine-tuned...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 480.075.9 MB/s, size: 57.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesOriginales\\val\\labels.cache... 74 images, 0 backgrounds, 0 corrupt: 100%|██████████| 74/74 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:06<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124       0.52      0.542      0.484      0.195\n",
      "             carretera         33         62      0.441      0.435      0.336      0.142\n",
      "                   rio         45         62      0.598      0.649      0.632      0.247\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\val38\u001b[0m\n",
      "  Precision: 0.5198 (51.98%)\n",
      "  Recall:    0.5422 (54.22%)\n",
      "  F1-Score:  0.5307 (53.07%)\n"
     ]
    }
   ],
   "source": [
    "modelo = 'model3_Orig.pt'\n",
    "\n",
    "# IMPORTANT: Load your fine-tuned model instead of the pre-trained one\n",
    "model = YOLO(modelo)  # Cambiar acá según el modelo a aplicar\n",
    "\n",
    "print(\"Modelo cargado:\", modelo)\n",
    "print(\"\\nMapeo de clases del modelo:\")\n",
    "for class_id, class_name in model.names.items():\n",
    "    print(f\"  Class {class_id}: {class_name}\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "print(\"\\nEvaluando el modelo fine-tuned...\")\n",
    "results = model.val(data=str(root / 'rio-carretera-differentiation_orig.yaml'))\n",
    "# Manejar arrays numpy para precision y recall\n",
    "if hasattr(results.box.p, 'mean'):\n",
    "    precision_mean = float(results.box.p.mean())\n",
    "    recall_mean = float(results.box.r.mean())\n",
    "else:\n",
    "    precision_mean = float(results.box.p)\n",
    "    recall_mean = float(results.box.r)\n",
    "print(f\"  Precision: {precision_mean:.4f} ({precision_mean*100:.2f}%)\")\n",
    "print(f\"  Recall:    {recall_mean:.4f} ({recall_mean*100:.2f}%)\")\n",
    "# Calcular F1-Score\n",
    "if precision_mean > 0 and recall_mean > 0:\n",
    "    f1_score = 2 * (precision_mean * recall_mean) / (precision_mean + recall_mean)\n",
    "    print(f\"  F1-Score:  {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"  F1-Score:  No calculable\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e834f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rapid fine-tuning...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data\\rio-carretera-differentiation.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=14, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=model3_Orig.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rapid_finetune11, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=3, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=2 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1413337  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,312,793 parameters, 25,312,777 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 174/1015 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.10.cv1.conv.weight'\n",
      "Freezing layer 'model.10.cv1.bn.weight'\n",
      "Freezing layer 'model.10.cv1.bn.bias'\n",
      "Freezing layer 'model.10.cv2.conv.weight'\n",
      "Freezing layer 'model.10.cv2.bn.weight'\n",
      "Freezing layer 'model.10.cv2.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.bias'\n",
      "Freezing layer 'model.13.cv1.conv.weight'\n",
      "Freezing layer 'model.13.cv1.bn.weight'\n",
      "Freezing layer 'model.13.cv1.bn.bias'\n",
      "Freezing layer 'model.13.cv2.conv.weight'\n",
      "Freezing layer 'model.13.cv2.bn.weight'\n",
      "Freezing layer 'model.13.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on Quadro T1000 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 354.952.3 MB/s, size: 406.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesFiltradas\\train\\labels.cache... 610 images, 0 backgrounds, 0 corrupt: 100%|██████████| 610/610 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1380.9259.6 MB/s, size: 378.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesFiltradas\\val\\labels.cache... 74 images, 0 backgrounds, 0 corrupt: 100%|██████████| 74/74 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      3.96G      2.181      2.764      2.239          9        640: 100%|██████████| 77/77 [02:18<00:00,  1.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.463      0.468      0.351      0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      4.01G      2.057      2.312      2.099          5        640: 100%|██████████| 77/77 [02:56<00:00,  2.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:11<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.719      0.476      0.517      0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      4.01G      2.049      2.247        2.1         13        640: 100%|██████████| 77/77 [01:56<00:00,  1.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:11<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.578      0.532      0.517      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      4.02G      1.985      2.171      2.048         14        640: 100%|██████████| 77/77 [02:28<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.472      0.551      0.457      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      4.01G      1.978      2.155      2.026          3        640: 100%|██████████| 77/77 [01:47<00:00,  1.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:14<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.608      0.532      0.524       0.24\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.210 hours.\n",
      "Optimizer stripped from c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\last.pt, 51.2MB\n",
      "Optimizer stripped from c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.pt, 51.2MB\n",
      "\n",
      "Validating c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,281,625 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:03<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.719      0.476      0.517      0.249\n",
      "             carretera         33         62      0.667      0.419      0.448      0.239\n",
      "                   rio         45         62      0.771      0.532      0.586      0.259\n",
      "Speed: 0.5ms preprocess, 37.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\u001b[0m\n",
      "Fine-tuning completed in 792.87 seconds\n",
      "Trainable parameters: 0 / 25,312,793 (0.0%)\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CPU (Intel Core(TM) i7-10850H 2.70GHz)\n",
      "YOLO11l summary (fused): 190 layers, 25,281,625 parameters, 0 gradients, 86.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (48.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.53'] not found, attempting AutoUpdate...\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  7.4s, saved as 'c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.onnx' (96.7 MB)\n",
      "\n",
      "Export complete (10.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=c:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\rapid_finetune11\\weights\\best.onnx imgsz=640 data=data\\rio-carretera-differentiation.yaml  \n",
      "Visualize:       https://netron.app\n",
      "model3.pt\n"
     ]
    }
   ],
   "source": [
    "#Modelo Filtradas\n",
    "\n",
    "# Define paths\n",
    "root = Path('data')\n",
    "yaml_path = root / 'rio-carretera-differentiation.yaml'\n",
    "\n",
    "#Fine Tune / Correr Modelo\n",
    "print(\"Starting rapid fine-tuning...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('runs/detect', exist_ok=True)\n",
    "\n",
    "# Train with minimal epochs and a small batch size for quick results\n",
    "results = model.train(\n",
    "    data=str(yaml_path),              # Path to your data YAML\n",
    "    epochs=20,                         # Very few epochs for fast adaptation\n",
    "    imgsz=640,                        # Image size\n",
    "    batch=8,                          # Smaller batch size\n",
    "    patience=3,                       # Early stopping patience\n",
    "    name='rapid_finetune',            # Run name\n",
    "    pretrained=True,                  # Use pretrained weights\n",
    "    freeze=14,                        # Alternative way to freeze layers\n",
    "    optimizer='Adam',                 # Adam optimizer converges faster for fine-tuning\n",
    "    lr0=0.001,                        # Lower learning rate for fine-tuning\n",
    "    device='0' if torch.cuda.is_available() else 'cpu' # Use GPU if available\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Fine-tuning completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Count trainable vs total parameters\n",
    "trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.1%})\")\n",
    "\n",
    "# Save the model\n",
    "model.export(format=\"onnx\")  # Export to ONNX format for deployment\n",
    "model.save('model3.pt')\n",
    "print(f\"model3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8b9b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: model3.pt\n",
      "\n",
      "Mapeo de clases del modelo:\n",
      "  Class 0: carretera\n",
      "  Class 1: rio\n",
      "  Class 2: background\n",
      "\n",
      "Evaluando el modelo fine-tuned...\n",
      "Ultralytics 8.3.141  Python-3.9.12 torch-2.2.0+cu121 CUDA:0 (Quadro T1000, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,281,625 parameters, 0 gradients, 86.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2239.2566.3 MB/s, size: 389.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\notebooks\\data\\ImagenesFiltradas\\val\\labels.cache... 74 images, 0 backgrounds, 0 corrupt: 100%|██████████| 74/74 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         74        124      0.719      0.476      0.517      0.249\n",
      "             carretera         33         62      0.667      0.419      0.448      0.239\n",
      "                   rio         45         62      0.771      0.532      0.586      0.259\n",
      "Speed: 1.2ms preprocess, 32.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Camilo Daza\\Documents\\GitHub\\isis4825-proyecto-final\\runs\\detect\\val41\u001b[0m\n",
      "  Precision: 0.7190 (71.90%)\n",
      "  Recall:    0.4757 (47.57%)\n",
      "  F1-Score:  0.5726 (57.26%)\n"
     ]
    }
   ],
   "source": [
    "modelo = 'model3.pt'\n",
    "\n",
    "# IMPORTANT: Load your fine-tuned model instead of the pre-trained one\n",
    "model = YOLO(modelo)  # Cambiar acá según el modelo a aplicar\n",
    "\n",
    "print(\"Modelo cargado:\", modelo)\n",
    "print(\"\\nMapeo de clases del modelo:\")\n",
    "for class_id, class_name in model.names.items():\n",
    "    print(f\"  Class {class_id}: {class_name}\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "print(\"\\nEvaluando el modelo fine-tuned...\")\n",
    "results = model.val(data=str(root / 'rio-carretera-differentiation.yaml'))\n",
    "# Manejar arrays numpy para precision y recall\n",
    "if hasattr(results.box.p, 'mean'):\n",
    "    precision_mean = float(results.box.p.mean())\n",
    "    recall_mean = float(results.box.r.mean())\n",
    "else:\n",
    "    precision_mean = float(results.box.p)\n",
    "    recall_mean = float(results.box.r)\n",
    "print(f\"  Precision: {precision_mean:.4f} ({precision_mean*100:.2f}%)\")\n",
    "print(f\"  Recall:    {recall_mean:.4f} ({recall_mean*100:.2f}%)\")\n",
    "# Calcular F1-Score\n",
    "if precision_mean > 0 and recall_mean > 0:\n",
    "    f1_score = 2 * (precision_mean * recall_mean) / (precision_mean + recall_mean)\n",
    "    print(f\"  F1-Score:  {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"  F1-Score:  No calculable\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
